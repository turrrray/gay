{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud in Electricity and Gas Consumption #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score, roc_auc_score, precision_score, average_precision_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "seed = 69\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since 2 datasets were provided, we attempt to combine both datasets into 1 on the id columm. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df = pd.read_csv('invoice.csv')\n",
    "client_df = pd.read_csv('client.csv')\n",
    "\n",
    "combined_df = pd.merge(client_df, invoice_df, on='id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>date_x</th>\n",
       "      <th>dis</th>\n",
       "      <th>id</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>date_y</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>24/3/2014</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14302</td>\n",
       "      <td>14384</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29/3/2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12294</td>\n",
       "      <td>13678</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>23/3/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14624</td>\n",
       "      <td>14747</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13/7/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14747</td>\n",
       "      <td>14849</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15066</td>\n",
       "      <td>15638</td>\n",
       "      <td>12</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region      date_x  dis              id  catg  target      date_y  \\\n",
       "0     101  31/12/1994   60  train_Client_0    11       0   24/3/2014   \n",
       "1     101  31/12/1994   60  train_Client_0    11       0   29/3/2013   \n",
       "2     101  31/12/1994   60  train_Client_0    11       0   23/3/2015   \n",
       "3     101  31/12/1994   60  train_Client_0    11       0   13/7/2015   \n",
       "4     101  31/12/1994   60  train_Client_0    11       0  17/11/2016   \n",
       "\n",
       "   tarif_type  counter_number  counter_statue  ...  reading_remarque  \\\n",
       "0          11       1335667.0               0  ...                 8   \n",
       "1          11       1335667.0               0  ...                 6   \n",
       "2          11       1335667.0               0  ...                 8   \n",
       "3          11       1335667.0               0  ...                 8   \n",
       "4          11       1335667.0               0  ...                 9   \n",
       "\n",
       "   consommation_level_4  old_index  new_index  months_number  counter_type  \\\n",
       "0                     0      14302      14384              4          ELEC   \n",
       "1                     0      12294      13678              4          ELEC   \n",
       "2                     0      14624      14747              4          ELEC   \n",
       "3                     0      14747      14849              4          ELEC   \n",
       "4                     0      15066      15638             12          ELEC   \n",
       "\n",
       "  counter_coefficient  consommation_level_1  consommation_level_2  \\\n",
       "0                   1                    82                     0   \n",
       "1                   1                  1200                   184   \n",
       "2                   1                   123                     0   \n",
       "3                   1                   102                     0   \n",
       "4                   1                   572                     0   \n",
       "\n",
       "   consommation_level_3  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>dis</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>counter_code</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>204.746922</td>\n",
       "      <td>63.519156</td>\n",
       "      <td>11.353871</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>16.108279</td>\n",
       "      <td>1.951034e+11</td>\n",
       "      <td>0.050217</td>\n",
       "      <td>204.390755</td>\n",
       "      <td>7.463710</td>\n",
       "      <td>64.393150</td>\n",
       "      <td>1.575969e+04</td>\n",
       "      <td>1.639037e+04</td>\n",
       "      <td>22.744289</td>\n",
       "      <td>1.000154</td>\n",
       "      <td>443.065463</td>\n",
       "      <td>120.508706</td>\n",
       "      <td>28.196772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.620488</td>\n",
       "      <td>3.388720</td>\n",
       "      <td>3.661420</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>11.145881</td>\n",
       "      <td>2.071552e+12</td>\n",
       "      <td>0.396153</td>\n",
       "      <td>121.204514</td>\n",
       "      <td>1.374409</td>\n",
       "      <td>1230.465569</td>\n",
       "      <td>2.975733e+04</td>\n",
       "      <td>3.053707e+04</td>\n",
       "      <td>1670.624818</td>\n",
       "      <td>0.047150</td>\n",
       "      <td>592.249623</td>\n",
       "      <td>1396.817086</td>\n",
       "      <td>214.020756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.477220e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.799000e+03</td>\n",
       "      <td>2.165000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.857010e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.876000e+03</td>\n",
       "      <td>8.438000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.008740e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.092750e+04</td>\n",
       "      <td>2.164500e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.740000e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>343568.000000</td>\n",
       "      <td>2.800280e+06</td>\n",
       "      <td>2.870972e+06</td>\n",
       "      <td>231602.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>98889.000000</td>\n",
       "      <td>819886.000000</td>\n",
       "      <td>45360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region            dis           catg         target  \\\n",
       "count  500651.000000  500651.000000  500651.000000  500651.000000   \n",
       "mean      204.746922      63.519156      11.353871       0.062644   \n",
       "std       104.620488       3.388720       3.661420       0.242323   \n",
       "min       101.000000      60.000000      11.000000       0.000000   \n",
       "25%       101.000000      62.000000      11.000000       0.000000   \n",
       "50%       107.000000      62.000000      11.000000       0.000000   \n",
       "75%       307.000000      69.000000      11.000000       0.000000   \n",
       "max       399.000000      69.000000      51.000000       1.000000   \n",
       "\n",
       "          tarif_type  counter_number  counter_statue   counter_code  \\\n",
       "count  500651.000000    5.006510e+05   500651.000000  500651.000000   \n",
       "mean       16.108279    1.951034e+11        0.050217     204.390755   \n",
       "std        11.145881    2.071552e+12        0.396153     121.204514   \n",
       "min         9.000000    0.000000e+00        0.000000       5.000000   \n",
       "25%        11.000000    1.477220e+05        0.000000     202.000000   \n",
       "50%        11.000000    4.857010e+05        0.000000     203.000000   \n",
       "75%        11.000000    1.008740e+06        0.000000     207.000000   \n",
       "max        45.000000    2.740000e+13        5.000000     600.000000   \n",
       "\n",
       "       reading_remarque  consommation_level_4     old_index     new_index  \\\n",
       "count     500651.000000         500651.000000  5.006510e+05  5.006510e+05   \n",
       "mean           7.463710             64.393150  1.575969e+04  1.639037e+04   \n",
       "std            1.374409           1230.465569  2.975733e+04  3.053707e+04   \n",
       "min            6.000000              0.000000  0.000000e+00  0.000000e+00   \n",
       "25%            6.000000              0.000000  1.799000e+03  2.165000e+03   \n",
       "50%            8.000000              0.000000  7.876000e+03  8.438000e+03   \n",
       "75%            9.000000              0.000000  2.092750e+04  2.164500e+04   \n",
       "max            9.000000         343568.000000  2.800280e+06  2.870972e+06   \n",
       "\n",
       "       months_number  counter_coefficient  consommation_level_1  \\\n",
       "count  500651.000000        500651.000000         500651.000000   \n",
       "mean       22.744289             1.000154            443.065463   \n",
       "std      1670.624818             0.047150            592.249623   \n",
       "min         1.000000             1.000000              0.000000   \n",
       "25%         4.000000             1.000000             99.000000   \n",
       "50%         4.000000             1.000000            321.000000   \n",
       "75%         4.000000             1.000000            661.000000   \n",
       "max    231602.000000            20.000000          98889.000000   \n",
       "\n",
       "       consommation_level_2  consommation_level_3  \n",
       "count         500651.000000         500651.000000  \n",
       "mean             120.508706             28.196772  \n",
       "std             1396.817086            214.020756  \n",
       "min                0.000000              0.000000  \n",
       "25%                0.000000              0.000000  \n",
       "50%                0.000000              0.000000  \n",
       "75%                0.000000              0.000000  \n",
       "max           819886.000000          45360.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>date_x</th>\n",
       "      <th>dis</th>\n",
       "      <th>id</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>date_y</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>24/3/2014</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14302</td>\n",
       "      <td>14384</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29/3/2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12294</td>\n",
       "      <td>13678</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>23/3/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14624</td>\n",
       "      <td>14747</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13/7/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14747</td>\n",
       "      <td>14849</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15066</td>\n",
       "      <td>15638</td>\n",
       "      <td>12</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region      date_x  dis              id  catg  target      date_y  \\\n",
       "0     101  31/12/1994   60  train_Client_0    11       0   24/3/2014   \n",
       "1     101  31/12/1994   60  train_Client_0    11       0   29/3/2013   \n",
       "2     101  31/12/1994   60  train_Client_0    11       0   23/3/2015   \n",
       "3     101  31/12/1994   60  train_Client_0    11       0   13/7/2015   \n",
       "4     101  31/12/1994   60  train_Client_0    11       0  17/11/2016   \n",
       "\n",
       "   tarif_type  counter_number  counter_statue  ...  reading_remarque  \\\n",
       "0          11       1335667.0               0  ...                 8   \n",
       "1          11       1335667.0               0  ...                 6   \n",
       "2          11       1335667.0               0  ...                 8   \n",
       "3          11       1335667.0               0  ...                 8   \n",
       "4          11       1335667.0               0  ...                 9   \n",
       "\n",
       "   consommation_level_4  old_index  new_index  months_number  counter_type  \\\n",
       "0                     0      14302      14384              4          ELEC   \n",
       "1                     0      12294      13678              4          ELEC   \n",
       "2                     0      14624      14747              4          ELEC   \n",
       "3                     0      14747      14849              4          ELEC   \n",
       "4                     0      15066      15638             12          ELEC   \n",
       "\n",
       "  counter_coefficient  consommation_level_1  consommation_level_2  \\\n",
       "0                   1                    82                     0   \n",
       "1                   1                  1200                   184   \n",
       "2                   1                   123                     0   \n",
       "3                   1                   102                     0   \n",
       "4                   1                   572                     0   \n",
       "\n",
       "   consommation_level_3  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 500651\n",
      "Number of datapoints in each column: \n",
      "region                  500651\n",
      "date_x                  500651\n",
      "dis                     500651\n",
      "id                      500651\n",
      "catg                    500651\n",
      "target                  500651\n",
      "date_y                  500651\n",
      "tarif_type              500651\n",
      "counter_number          500651\n",
      "counter_statue          500651\n",
      "counter_code            500651\n",
      "reading_remarque        500651\n",
      "consommation_level_4    500651\n",
      "old_index               500651\n",
      "new_index               500651\n",
      "months_number           500651\n",
      "counter_type            500651\n",
      "counter_coefficient     500651\n",
      "consommation_level_1    500651\n",
      "consommation_level_2    500651\n",
      "consommation_level_3    500651\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset: {len(combined_df)}\")\n",
    "print(f\"Number of datapoints in each column: \\n{combined_df.count()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31363\n",
      "proportion of fraud: 0.06264443694310008\n"
     ]
    }
   ],
   "source": [
    "number_of_fraud = sum(combined_df[\"target\"] == 1)\n",
    "print(number_of_fraud)\n",
    "print(f\"proportion of fraud: {number_of_fraud/len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have created 3 new variables, described as such:\n",
    "##### delta_start_invoice: diff between join and transaction date\n",
    "##### delta_index: diff between old and new index\n",
    "##### delta_transactions: diff between transactions over the same client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>id</th>\n",
       "      <th>delta_start_invoice</th>\n",
       "      <th>delta_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2005-10-17</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>3943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4073</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-06-23</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4192</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4309</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4440</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    join_date transaction_date              id  delta_start_invoice  \\\n",
       "22 1994-12-31       2005-10-17  train_Client_0                 3943   \n",
       "23 1994-12-31       2006-02-24  train_Client_0                 4073   \n",
       "24 1994-12-31       2006-06-23  train_Client_0                 4192   \n",
       "25 1994-12-31       2006-10-18  train_Client_0                 4309   \n",
       "28 1994-12-31       2007-02-26  train_Client_0                 4440   \n",
       "\n",
       "    delta_transactions  \n",
       "22                 0.0  \n",
       "23               130.0  \n",
       "24               119.0  \n",
       "25               117.0  \n",
       "28               131.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dates = {'join_date': combined_df['date_x'], 'transaction_date': combined_df['date_y'], 'id': combined_df['id']}\n",
    "dates_df = pd.DataFrame(dates)\n",
    "\n",
    "dates_df['join_date'] = pd.to_datetime(dates_df['join_date'] , format='%d/%m/%Y')\n",
    "dates_df['transaction_date'] = pd.to_datetime(dates_df['transaction_date'], format='%d/%m/%Y')\n",
    "\n",
    "# Calculate the difference in days between transaction and join date\n",
    "dates_df['delta_start_invoice'] = (dates_df['transaction_date']- dates_df['join_date']).dt.days\n",
    "\n",
    "# Create new delta_transactions (diff between transaction dates for each client)\n",
    "dates_df = dates_df.sort_values(['id', 'delta_start_invoice'])\n",
    "dates_df['delta_transactions'] = dates_df.groupby('id')['delta_start_invoice'].diff().fillna(0)\n",
    "\n",
    "dates_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add new delta_start_invoice, delta_index and consommation_sum to combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['delta_index'] = combined_df['new_index'] - combined_df['old_index']\n",
    "combined_df['delta_start_invoice'] = dates_df['delta_start_invoice']\n",
    "combined_df['delta_transactions'] = dates_df['delta_transactions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new dataframe for one-hot encoding categorical variables (dis, catg, region, tarif_type, counter_statue, counter_code, reading_remarque, counter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['dis', 'catg', 'region', 'tarif_type', 'counter_statue', 'counter_code', 'counter_type']\n",
    "categorical_df = pd.get_dummies(combined_df, columns=categorical_vars, prefix=categorical_vars)\n",
    "categorical_df = categorical_df.groupby('id').agg({col: 'max' for col in categorical_df.columns if col != 'id'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agg function to group the transactions with each client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">consommation_level_1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">consommation_level_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">consommation_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">delta_index</th>\n",
       "      <th colspan=\"4\" halign=\"left\">delta_start_invoice</th>\n",
       "      <th colspan=\"4\" halign=\"left\">reading_remarque</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_Client_0</th>\n",
       "      <td>12334</td>\n",
       "      <td>352.400000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>310.343472</td>\n",
       "      <td>370</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.568935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>267.0</td>\n",
       "      <td>341.553930</td>\n",
       "      <td>213142</td>\n",
       "      <td>6089.771429</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>1358.574709</td>\n",
       "      <td>244</td>\n",
       "      <td>6.971429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.248192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_1</th>\n",
       "      <td>20629</td>\n",
       "      <td>557.540541</td>\n",
       "      <td>520.0</td>\n",
       "      <td>197.935960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>197.935960</td>\n",
       "      <td>132603</td>\n",
       "      <td>3583.864865</td>\n",
       "      <td>3509.0</td>\n",
       "      <td>1457.748762</td>\n",
       "      <td>267</td>\n",
       "      <td>7.216216</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.377097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_10</th>\n",
       "      <td>14375</td>\n",
       "      <td>798.611111</td>\n",
       "      <td>655.5</td>\n",
       "      <td>513.841374</td>\n",
       "      <td>682</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.748942</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>655.5</td>\n",
       "      <td>646.808386</td>\n",
       "      <td>165982</td>\n",
       "      <td>9221.222222</td>\n",
       "      <td>8678.0</td>\n",
       "      <td>1526.789733</td>\n",
       "      <td>127</td>\n",
       "      <td>7.055556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.258955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_100</th>\n",
       "      <td>24</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.607011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.607011</td>\n",
       "      <td>91275</td>\n",
       "      <td>4563.750000</td>\n",
       "      <td>4545.5</td>\n",
       "      <td>774.520692</td>\n",
       "      <td>123</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_1000</th>\n",
       "      <td>9292</td>\n",
       "      <td>663.714286</td>\n",
       "      <td>770.0</td>\n",
       "      <td>224.831365</td>\n",
       "      <td>1468</td>\n",
       "      <td>104.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.155320</td>\n",
       "      <td>1643</td>\n",
       "      <td>117.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>770.0</td>\n",
       "      <td>633.485669</td>\n",
       "      <td>13497</td>\n",
       "      <td>964.071429</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>506.611437</td>\n",
       "      <td>124</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.363137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  consommation_level_1                                 \\\n",
       "                                   sum        mean median         std   \n",
       "id                                                                      \n",
       "train_Client_0                   12334  352.400000  267.0  310.343472   \n",
       "train_Client_1                   20629  557.540541  520.0  197.935960   \n",
       "train_Client_10                  14375  798.611111  655.5  513.841374   \n",
       "train_Client_100                    24    1.200000    0.0    3.607011   \n",
       "train_Client_1000                 9292  663.714286  770.0  224.831365   \n",
       "\n",
       "                  consommation_level_2                                 \\\n",
       "                                   sum        mean median         std   \n",
       "id                                                                      \n",
       "train_Client_0                     370   10.571429    0.0   43.568935   \n",
       "train_Client_1                       0    0.000000    0.0    0.000000   \n",
       "train_Client_10                    682   37.888889    0.0  160.748942   \n",
       "train_Client_100                     0    0.000000    0.0    0.000000   \n",
       "train_Client_1000                 1468  104.857143    0.0  167.155320   \n",
       "\n",
       "                  consommation_level_3              ... delta_index  \\\n",
       "                                   sum        mean  ...      median   \n",
       "id                                                  ...               \n",
       "train_Client_0                       0    0.000000  ...       267.0   \n",
       "train_Client_1                       0    0.000000  ...       520.0   \n",
       "train_Client_10                      0    0.000000  ...       655.5   \n",
       "train_Client_100                     0    0.000000  ...         0.0   \n",
       "train_Client_1000                 1643  117.357143  ...       770.0   \n",
       "\n",
       "                              delta_start_invoice                       \\\n",
       "                          std                 sum         mean  median   \n",
       "id                                                                       \n",
       "train_Client_0     341.553930              213142  6089.771429  6047.0   \n",
       "train_Client_1     197.935960              132603  3583.864865  3509.0   \n",
       "train_Client_10    646.808386              165982  9221.222222  8678.0   \n",
       "train_Client_100     3.607011               91275  4563.750000  4545.5   \n",
       "train_Client_1000  633.485669               13497   964.071429  1010.0   \n",
       "\n",
       "                               reading_remarque                             \n",
       "                           std              sum      mean median       std  \n",
       "id                                                                          \n",
       "train_Client_0     1358.574709              244  6.971429    6.0  1.248192  \n",
       "train_Client_1     1457.748762              267  7.216216    6.0  1.377097  \n",
       "train_Client_10    1526.789733              127  7.055556    6.0  1.258955  \n",
       "train_Client_100    774.520692              123  6.150000    6.0  0.670820  \n",
       "train_Client_1000   506.611437              124  8.857143    9.0  0.363137  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = ['sum', 'mean', 'median', 'std']\n",
    "\n",
    "selected_columns = ['consommation_level_1', \n",
    "                    'consommation_level_2', 'consommation_level_3', 'consommation_level_4',\n",
    "                    'delta_index', 'delta_start_invoice', 'id', 'reading_remarque']\n",
    "\n",
    "# Create a new dataframe with the desired aggregate functions\n",
    "numerical_df = combined_df[selected_columns].groupby('id').agg(stats)\n",
    "\n",
    "numerical_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining numerical and cat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21652 entries, train_Client_0 to train_Client_128438\n",
      "Columns: 116 entries, ('consommation_level_1', 'sum') to counter_type_GAZ\n",
      "dtypes: bool(85), float64(22), int64(9)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "to_drop = ['region', 'date_x', 'dis', 'id', 'catg', 'target', 'date_y', 'tarif_type', 'counter_number', \n",
    "           'counter_statue', 'counter_code', 'reading_remarque', 'consommation_level_4', 'old_index',\n",
    "           'new_index', 'months_number', 'counter_type', 'counter_coefficient', 'consommation_level_1',\n",
    "           'consommation_level_2', 'consommation_level_3']\n",
    "\n",
    "client_summary = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "\n",
    "# Identify existing columns in the DataFrame\n",
    "existing_columns = [col for col in to_drop if col in client_summary.columns]\n",
    "\n",
    "# Drop existing columns from the DataFrame\n",
    "client_summary = client_summary.drop(columns=existing_columns)\n",
    "\n",
    "client_summary.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    20576\n",
       "1     1076\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_summary['target'] = combined_df.groupby('id')['target'].apply(lambda x: 1 if x.any() else 0)\n",
    "client_summary['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original split without data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = client_summary.drop('target', axis=1)\n",
    "\n",
    "# Flatten multi-level column names\n",
    "X.columns = [''.join(map(str, col)).strip() for col in X.columns.to_flat_index()]\n",
    "\n",
    "y = client_summary['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the low proportion of fraud cases, we performed synthetic oversampling of fraud cases with SMOTE and undersampled non-fraud cases with Tomek's link with three different methods:\n",
    "#### 1) SMOTE + Tomek's Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consommation_level_1sum</th>\n",
       "      <th>consommation_level_1mean</th>\n",
       "      <th>consommation_level_1median</th>\n",
       "      <th>consommation_level_1std</th>\n",
       "      <th>consommation_level_2sum</th>\n",
       "      <th>consommation_level_2mean</th>\n",
       "      <th>consommation_level_2median</th>\n",
       "      <th>consommation_level_2std</th>\n",
       "      <th>consommation_level_3sum</th>\n",
       "      <th>consommation_level_3mean</th>\n",
       "      <th>...</th>\n",
       "      <th>counter_code_450</th>\n",
       "      <th>counter_code_453</th>\n",
       "      <th>counter_code_467</th>\n",
       "      <th>counter_code_483</th>\n",
       "      <th>counter_code_506</th>\n",
       "      <th>counter_code_532</th>\n",
       "      <th>counter_code_565</th>\n",
       "      <th>counter_code_600</th>\n",
       "      <th>counter_type_ELEC</th>\n",
       "      <th>counter_type_GAZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.685554</td>\n",
       "      <td>-0.221794</td>\n",
       "      <td>-0.425497</td>\n",
       "      <td>0.028572</td>\n",
       "      <td>-0.201780</td>\n",
       "      <td>-0.225311</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>-0.130865</td>\n",
       "      <td>-0.463374</td>\n",
       "      <td>-0.407162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>-0.033906</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>1.177256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.796658</td>\n",
       "      <td>0.197327</td>\n",
       "      <td>0.244187</td>\n",
       "      <td>0.327422</td>\n",
       "      <td>-0.307390</td>\n",
       "      <td>-0.270927</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>-0.192952</td>\n",
       "      <td>-0.463374</td>\n",
       "      <td>-0.407162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>-0.033906</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>-0.849433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.355386</td>\n",
       "      <td>0.140101</td>\n",
       "      <td>0.195116</td>\n",
       "      <td>-0.169480</td>\n",
       "      <td>-0.288245</td>\n",
       "      <td>-0.257144</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>-0.168790</td>\n",
       "      <td>-0.463374</td>\n",
       "      <td>-0.407162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>-0.033906</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>-0.849433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.961451</td>\n",
       "      <td>-0.663271</td>\n",
       "      <td>-0.561166</td>\n",
       "      <td>-0.373705</td>\n",
       "      <td>-0.307390</td>\n",
       "      <td>-0.270927</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>-0.192952</td>\n",
       "      <td>-0.463374</td>\n",
       "      <td>-0.407162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>-0.033906</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>-0.849433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.052457</td>\n",
       "      <td>-0.539388</td>\n",
       "      <td>-0.786319</td>\n",
       "      <td>0.036666</td>\n",
       "      <td>-0.272099</td>\n",
       "      <td>-0.253990</td>\n",
       "      <td>-0.205524</td>\n",
       "      <td>-0.140615</td>\n",
       "      <td>-0.368899</td>\n",
       "      <td>-0.366908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.040972</td>\n",
       "      <td>-0.037811</td>\n",
       "      <td>-0.033906</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.007879</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>0.048943</td>\n",
       "      <td>1.177256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   consommation_level_1sum  consommation_level_1mean  \\\n",
       "0                 0.685554                 -0.221794   \n",
       "1                 0.796658                  0.197327   \n",
       "2                 0.355386                  0.140101   \n",
       "3                -0.961451                 -0.663271   \n",
       "4                -0.052457                 -0.539388   \n",
       "\n",
       "   consommation_level_1median  consommation_level_1std  \\\n",
       "0                   -0.425497                 0.028572   \n",
       "1                    0.244187                 0.327422   \n",
       "2                    0.195116                -0.169480   \n",
       "3                   -0.561166                -0.373705   \n",
       "4                   -0.786319                 0.036666   \n",
       "\n",
       "   consommation_level_2sum  consommation_level_2mean  \\\n",
       "0                -0.201780                 -0.225311   \n",
       "1                -0.307390                 -0.270927   \n",
       "2                -0.288245                 -0.257144   \n",
       "3                -0.307390                 -0.270927   \n",
       "4                -0.272099                 -0.253990   \n",
       "\n",
       "   consommation_level_2median  consommation_level_2std  \\\n",
       "0                   -0.205524                -0.130865   \n",
       "1                   -0.205524                -0.192952   \n",
       "2                   -0.205524                -0.168790   \n",
       "3                   -0.205524                -0.192952   \n",
       "4                   -0.205524                -0.140615   \n",
       "\n",
       "   consommation_level_3sum  consommation_level_3mean  ...  counter_code_450  \\\n",
       "0                -0.463374                 -0.407162  ...         -0.011142   \n",
       "1                -0.463374                 -0.407162  ...         -0.011142   \n",
       "2                -0.463374                 -0.407162  ...         -0.011142   \n",
       "3                -0.463374                 -0.407162  ...         -0.011142   \n",
       "4                -0.368899                 -0.366908  ...         -0.011142   \n",
       "\n",
       "   counter_code_453  counter_code_467  counter_code_483  counter_code_506  \\\n",
       "0         -0.040972         -0.037811         -0.033906         -0.035255   \n",
       "1         -0.040972         -0.037811         -0.033906         -0.035255   \n",
       "2         -0.040972         -0.037811         -0.033906         -0.035255   \n",
       "3         -0.040972         -0.037811         -0.033906         -0.035255   \n",
       "4         -0.040972         -0.037811         -0.033906         -0.035255   \n",
       "\n",
       "   counter_code_532  counter_code_565  counter_code_600  counter_type_ELEC  \\\n",
       "0         -0.007879         -0.007879         -0.011142           0.048943   \n",
       "1         -0.007879         -0.007879         -0.011142           0.048943   \n",
       "2         -0.007879         -0.007879         -0.011142           0.048943   \n",
       "3         -0.007879         -0.007879         -0.011142           0.048943   \n",
       "4         -0.007879         -0.007879         -0.011142           0.048943   \n",
       "\n",
       "   counter_type_GAZ  \n",
       "0          1.177256  \n",
       "1         -0.849433  \n",
       "2         -0.849433  \n",
       "3         -0.849433  \n",
       "4          1.177256  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the oversampling strategy using SMOTE and Tomek\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "smote = SMOTE(random_state=seed)\n",
    "tomek = TomekLinks()\n",
    "\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state= seed)\n",
    "\n",
    "\n",
    "# under and oversampling of data using Tomek and SMOTE\n",
    "X_train1, y_train1 = tomek.fit_resample(X_train1, y_train1)\n",
    "X_train1, y_train1 = smote.fit_resample(X_train1, y_train1)\n",
    "\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train1_standardized = pd.DataFrame(scaler.fit_transform(X_train1), columns=X_train1.columns)\n",
    "X_test1_standardized = pd.DataFrame(scaler.transform(X_test1), columns=X_test1.columns)\n",
    "\n",
    "# Normalise the data\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train1_normalized = pd.DataFrame(scaler_minmax.fit_transform(X_train1), columns=X_train1.columns)\n",
    "X_test1_normmalized = pd.DataFrame(scaler_minmax.transform(X_test1), columns=X_test1.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) SMOTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Oversampling of data using SMOTE\n",
    "X_train2, y_train2 = smote.fit_resample(X_train2, y_train2)\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train2_standardized = pd.DataFrame(scaler.fit_transform(X_train2), columns=X_train2.columns)\n",
    "X_test2_standardized = pd.DataFrame(scaler.transform(X_test2), columns=X_test2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) SMOTE + ENN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ADASYN+ENN resampling strategy\n",
    "smote_enn = SMOTEENN(random_state=seed)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Resampling of data using ADASYN+ENN\n",
    "X_train3, y_train3 = smote_enn.fit_resample(X_train3, y_train3)\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train3_standardized = pd.DataFrame(scaler.fit_transform(X_train3), columns=X_train3.columns)\n",
    "X_test3_standardized = pd.DataFrame(scaler.transform(X_test3), columns=X_test3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Bool to int\n",
    "for df in [X_train1_standardized, X_train2_standardized, X_train3_standardized,\n",
    "           X_test1_standardized, X_test2_standardized, X_test3_standardized]:\n",
    "    \n",
    "    df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32222 entries, 0 to 32221\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 28.5 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32922 entries, 0 to 32921\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 29.1 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26352 entries, 0 to 26351\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 23.3 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 3.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 3.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4331 entries, 0 to 4330\n",
      "Columns: 116 entries, consommation_level_1sum to counter_type_GAZ\n",
      "dtypes: float64(116)\n",
      "memory usage: 3.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for data in [X_train1_standardized, X_train2_standardized, X_train3_standardized,\n",
    "           X_test1_standardized, X_test2_standardized, X_test3_standardized]:\n",
    "    print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing between the fraud and non-fraud cases for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 17321 entries, train_Client_119780 to train_Client_105306\n",
      "Series name: target\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "17321 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 786.7+ KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = [\n",
    "    (y_train.value_counts(), 'original'),\n",
    "    (y_train1.value_counts(), 'train1'),\n",
    "    (y_train2.value_counts(), 'train2'),\n",
    "    (y_train3.value_counts(), 'train3')\n",
    "]\n",
    "\n",
    "# Create the bar graph\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(counts))\n",
    "width = 0.35\n",
    "\n",
    "# Plot the negative cases\n",
    "non_fraud = ax.bar(x - width/2, [count[0].get(0, 0) for count in counts], width, label='non-fraud')\n",
    "\n",
    "# Plot the positive cases\n",
    "fraud = ax.bar(x + width/2, [count[0].get(1, 0) for count in counts], width, label='fraud')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([count[1] for count in counts])\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Comparison of fraud and non-fraud cases')\n",
    "ax.legend()\n",
    "\n",
    "for bar in non_fraud + fraud:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(int(height)),\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We chose to use f2 score over f1 score in comparing our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scorer\n",
    "def f2_score(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "f2_scorer = make_scorer(f2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create StratifiedKFold for cross-validation with reduced splits\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'f2': f2_scorer,\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score),\n",
    "    'pr_auc': make_scorer(average_precision_score)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we use the default LR model to compare between using standardized or normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.77783576 0.9631173  0.97360248 0.97259338 0.96291457]\n",
      "Mean F2 Score: 0.9300126974047667\n"
     ]
    }
   ],
   "source": [
    "# Comparing performance of standardized and nominalized datasets for method 1 (SMOTE + Tomak's Link)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "LR = LogisticRegression()\n",
    "\n",
    "# Perform cross-validation (std)\n",
    "cross_val_results_std = cross_val_score(LR, X_train1_standardized, y_train1, cv=5, scoring=f2_scorer)\n",
    "\n",
    "# Print cross-validation F2 score (std)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_std)\n",
    "print(\"Mean F2 Score:\", cross_val_results_std.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.77397663 0.96266335 0.97354202 0.97134154 0.96322569]\n",
      "Mean F2 Score: 0.928949843279765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation (nom)\n",
    "cross_val_results_nom = cross_val_score(LR, X_train1_normalized, y_train1, cv=5, scoring=f2_scorer)\n",
    "\n",
    "# Print cross-validation F2 score (nom)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_nom)\n",
    "print(\"Mean F2 Score:\", cross_val_results_nom.mean())\n",
    "\n",
    "# We pick standardising over norminalizing given its slightly better mean F2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 84.70152441660564\n",
      "Mean SCORE_TIME: 0.013197024663289389\n",
      "Mean TEST_F2: 0.9343133549023314\n",
      "Mean TEST_PRECISION: 0.9748086389616039\n",
      "Mean TEST_ACCURACY: 0.9504065361319635\n",
      "Mean TEST_ROC_AUC: 0.950406550293487\n",
      "Mean TEST_PR_AUC: 0.9390610619080602\n"
     ]
    }
   ],
   "source": [
    "# Initialize logistic regression model\n",
    "LR = LogisticRegression()\n",
    "\n",
    "param_grid_LR = [    \n",
    "    {'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter' : [100, 1000, 2500]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform RandomizedSearchCV with reduced iterations\n",
    "LR_randomized = RandomizedSearchCV(\n",
    "    LR,\n",
    "    param_distributions=param_grid_LR,\n",
    "    n_iter=3,\n",
    "    cv=skf,\n",
    "    scoring=f2_scorer,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "cv_LR_m1 = cross_validate(LR_randomized, X_train1_standardized, y_train1, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_LR_m1.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 83.74887657165527\n",
      "Mean SCORE_TIME: 0.011704285939534506\n",
      "Mean TEST_F2: 0.934664671198577\n",
      "Mean TEST_PRECISION: 0.9752839389698621\n",
      "Mean TEST_ACCURACY: 0.9507927829414982\n",
      "Mean TEST_ROC_AUC: 0.9507927829414982\n",
      "Mean TEST_PR_AUC: 0.9396535977116375\n"
     ]
    }
   ],
   "source": [
    "cv_LR_m2 = cross_validate(LR_randomized, X_train2_standardized, y_train2, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_LR_m2.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 70.97663633028667\n",
      "Mean SCORE_TIME: 0.010557730992635092\n",
      "Mean TEST_F2: 0.9400098255533615\n",
      "Mean TEST_PRECISION: 0.9767434235566091\n",
      "Mean TEST_ACCURACY: 0.9482012750455374\n",
      "Mean TEST_ROC_AUC: 0.9509460937334623\n",
      "Mean TEST_PR_AUC: 0.9487634336919667\n"
     ]
    }
   ],
   "source": [
    "cv_LR_m3 = cross_validate(LR_randomized, X_train3_standardized, y_train3, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_LR_m3.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Using SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM was split into 3 cells otherwise it takes too long to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.78952492 0.96699138 0.97410642 0.97341843 0.96563062]\n",
      "Mean F2 Score: 0.9339343542360814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "SVM = svm.SVC(kernel='linear', random_state=seed)\n",
    "\n",
    "cross_val_results_m1_SVM = cross_val_score(SVM, X_train1_standardized, y_train1, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m1_SVM)\n",
    "print(f\"Mean F2 Score: {cross_val_results_m1_SVM.mean()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.79581484 0.96610581 0.97460452 0.97270246 0.9656952 ]\n",
      "Mean F2 Score: 0.9339343542360814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_results_m2_SVM = cross_val_score(SVM, X_train2_standardized, y_train2, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m2_SVM)\n",
    "print(f\"Mean F2 Score: {cross_val_results_m2_SVM.mean()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.79550202 0.96894825 0.97749367 0.97565855 0.96751601]\n",
      "Mean F2 Score: 0.9339343542360814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_results_m3_SVM = cross_val_score(SVM, X_train3_standardized, y_train3, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m3_SVM)\n",
    "print(f\"Mean F2 Score: {cross_val_results_m3_SVM.mean()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Using GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 3.443812052408854\n",
      "Mean SCORE_TIME: 0.04821364084879557\n",
      "Mean TEST_F2: 0.9631372107115617\n",
      "Mean TEST_PRECISION: 0.9822584989452366\n",
      "Mean TEST_ACCURACY: 0.9705790813795229\n",
      "Mean TEST_ROC_AUC: 0.9705790725441051\n",
      "Mean TEST_PR_AUC: 0.9622310210501199\n"
     ]
    }
   ],
   "source": [
    "# Create a LightGBM classifier\n",
    "GBM = lgb.LGBMClassifier(force_row_wise=True, verbose=-1,  random_state=seed)\n",
    "\n",
    "param_grid_GBM = {\n",
    "    'num_leaves': [31, 50, 70, 90, 127],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'min_child_samples': [20, 50, 100, 300],\n",
    "    'min_child_weight': [0.001, 0.01, 0.1, 1],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 1, 2, 5],\n",
    "    'reg_lambda': [0, 0.1, 1, 2, 5]\n",
    "}\n",
    "\n",
    "\n",
    "GBM_randomized = RandomizedSearchCV(\n",
    "    GBM,\n",
    "    param_distributions=param_grid_GBM,\n",
    "    n_iter=3,\n",
    "    cv=skf,\n",
    "    scoring=f2_scorer,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "\n",
    "cv_GBM_m1 = cross_validate(GBM_randomized, X_train1_standardized, y_train1, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_GBM_m1.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 3.474242607752482\n",
      "Mean SCORE_TIME: 0.05310869216918945\n",
      "Mean TEST_F2: 0.9622290299604366\n",
      "Mean TEST_PRECISION: 0.9809657804299898\n",
      "Mean TEST_ACCURACY: 0.9695340501792115\n",
      "Mean TEST_ROC_AUC: 0.9695340501792115\n",
      "Mean TEST_PR_AUC: 0.960601511590645\n"
     ]
    }
   ],
   "source": [
    "cv_GBM_m2 = cross_validate(GBM_randomized, X_train2_standardized, y_train2, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_GBM_m2.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 2.948671499888102\n",
      "Mean SCORE_TIME: 0.044251600901285805\n",
      "Mean TEST_F2: 0.9671805995652155\n",
      "Mean TEST_PRECISION: 0.9775311531138434\n",
      "Mean TEST_ACCURACY: 0.9672131147540983\n",
      "Mean TEST_ROC_AUC: 0.9676315116547741\n",
      "Mean TEST_PR_AUC: 0.9631034028607249\n"
     ]
    }
   ],
   "source": [
    "cv_GBM_m3 = cross_validate(GBM_randomized, X_train3_standardized, y_train3, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_GBM_m3.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 27.650081237157185\n",
      "Mean SCORE_TIME: 0.34339269002278644\n",
      "Mean TEST_F2: 0.9707066808890271\n",
      "Mean TEST_PRECISION: 0.9749814155220008\n",
      "Mean TEST_ACCURACY: 0.9723791130605149\n",
      "Mean TEST_ROC_AUC: 0.9723792371404886\n",
      "Mean TEST_PR_AUC: 0.9605601798546438\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "\n",
    "param_grid_RF = {\n",
    "    'n_estimators':[100, 200, 300, 400, 500],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "RF_randomized = RandomizedSearchCV(\n",
    "    RF,\n",
    "    param_distributions=param_grid_RF,\n",
    "    n_iter=3,\n",
    "    cv=skf,\n",
    "    scoring=f2_scorer,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "\n",
    "cv_RF_m1 = cross_validate(RF_randomized, X_train1_standardized, y_train1, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_RF_m1.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 27.873144547144573\n",
      "Mean SCORE_TIME: 0.3575012683868408\n",
      "Mean TEST_F2: 0.9711662844851198\n",
      "Mean TEST_PRECISION: 0.9764073873735967\n",
      "Mean TEST_ACCURACY: 0.9732094040459267\n",
      "Mean TEST_ROC_AUC: 0.9732094040459267\n",
      "Mean TEST_PR_AUC: 0.9620503199753777\n"
     ]
    }
   ],
   "source": [
    "cv_RF_m2 = cross_validate(RF_randomized, X_train2_standardized, y_train2, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_RF_m2.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Mean FIT_TIME: 21.540926615397137\n",
      "Mean SCORE_TIME: 0.26586437225341797\n",
      "Mean TEST_F2: 0.9736070071298841\n",
      "Mean TEST_PRECISION: 0.9622583395401043\n",
      "Mean TEST_ACCURACY: 0.9647844565877354\n",
      "Mean TEST_ROC_AUC: 0.9628885038666978\n",
      "Mean TEST_PR_AUC: 0.9530283950019086\n"
     ]
    }
   ],
   "source": [
    "cv_RF_m3 = cross_validate(RF_randomized, X_train3_standardized, y_train3, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_RF_m3.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Using ADA boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FIT_TIME: 39.2658744653066\n",
      "Mean SCORE_TIME: 0.549990733464559\n",
      "Mean TEST_F2: 0.9453500022240268\n",
      "Mean TEST_PRECISION: 0.9741055459284329\n",
      "Mean TEST_ACCURACY: 0.9567376374059012\n",
      "Mean TEST_ROC_AUC: 0.9567377729515281\n",
      "Mean TEST_PR_AUC: 0.9449103152368141\n"
     ]
    }
   ],
   "source": [
    "ADA = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200)\n",
    "\n",
    "param_grid_ADA = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "ADA_randomized = RandomizedSearchCV(\n",
    "    ADA,\n",
    "    param_distributions=param_grid_ADA,\n",
    "    n_iter=3,\n",
    "    cv=skf,\n",
    "    scoring=f2_scorer,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "cv_ADA_m1 = cross_validate(ADA_randomized, X_train1_standardized, y_train1, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_ADA_m1.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FIT_TIME: 40.8813308874766\n",
      "Mean SCORE_TIME: 0.632824977238973\n",
      "Mean TEST_F2: 0.9451257589752241\n",
      "Mean TEST_PRECISION: 0.9732867489754997\n",
      "Mean TEST_ACCURACY: 0.9562906263288986\n",
      "Mean TEST_ROC_AUC: 0.9562906263288986\n",
      "Mean TEST_PR_AUC: 0.9441035841432409\n"
     ]
    }
   ],
   "source": [
    "cv_ADA_m2 = cross_validate(ADA_randomized, X_train2_standardized, y_train2, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_ADA_m2.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean FIT_TIME: 32.54342325528463\n",
      "Mean SCORE_TIME: 0.49530752499898273\n",
      "Mean TEST_F2: 0.9523508000264767\n",
      "Mean TEST_PRECISION: 0.9705378071125846\n",
      "Mean TEST_ACCURACY: 0.9539313904068002\n",
      "Mean TEST_ROC_AUC: 0.9549067090678469\n",
      "Mean TEST_PR_AUC: 0.9496617395889745\n"
     ]
    }
   ],
   "source": [
    "cv_ADA_m3 = cross_validate(ADA_randomized, X_train3_standardized, y_train3, cv=skf, scoring=scoring_metrics)\n",
    "\n",
    "for metric, score in cv_ADA_m3.items():\n",
    "    print(f\"Mean {metric.upper()}: {np.mean(score)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We note that random forest performs best from our cross validation with all 3 datasets, hence will will be focusing on tuning that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "F2 score: 0.151356993736952\n"
     ]
    }
   ],
   "source": [
    "RF_m1 = RF_randomized.fit(X_train1_standardized, y_train1)\n",
    "best_model_m1 = RF_randomized.best_estimator_\n",
    "best_model_m1.fit(X_train1_standardized, y_train1)\n",
    "y_pred_m1 = best_model_m1.predict(X_test1_standardized)\n",
    "\n",
    "f2_score = fbeta_score(y_test1, y_pred_m1, beta=2)\n",
    "print(f'F2 score: {f2_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "F2 score: 0.2351851851851852\n"
     ]
    }
   ],
   "source": [
    "RF_m2 = RF_randomized.fit(X_train2_standardized, y_train2)\n",
    "best_model_m2 = RF_randomized.best_estimator_\n",
    "best_model_m2.fit(X_train2_standardized, y_train2)\n",
    "y_pred_m2 = best_model_m2.predict(X_test1_standardized)\n",
    "f2_score = fbeta_score(y_test1, y_pred_m2, beta=2)\n",
    "print(f'F2 score: {f2_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "F2 score: 0.27631578947368424\n"
     ]
    }
   ],
   "source": [
    "RF_m3 = RF_randomized.fit(X_train3_standardized, y_train3)\n",
    "best_model_m3 = RF_randomized.best_estimator_\n",
    "best_model_m3.fit(X_train3_standardized, y_train3)\n",
    "y_pred_m3 = best_model_m3.predict(X_test3_standardized)\n",
    "f2_score = fbeta_score(y_test3, y_pred_m3, beta=2)\n",
    "print(f'F2 score: {f2_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
