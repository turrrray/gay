{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud in Electricity and Gas Consumption #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since 2 datasets were provided, we attempt to combine both datasets into 1 on the id columm. ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "seed = 69\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice_df = pd.read_csv('invoice.csv')\n",
    "client_df = pd.read_csv('client.csv')\n",
    "\n",
    "combined_df = pd.merge(client_df, invoice_df, on='id', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>date_x</th>\n",
       "      <th>dis</th>\n",
       "      <th>id</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>date_y</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>24/3/2014</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14302</td>\n",
       "      <td>14384</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29/3/2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12294</td>\n",
       "      <td>13678</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>23/3/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14624</td>\n",
       "      <td>14747</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13/7/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14747</td>\n",
       "      <td>14849</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15066</td>\n",
       "      <td>15638</td>\n",
       "      <td>12</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region      date_x  dis              id  catg  target      date_y  \\\n",
       "0     101  31/12/1994   60  train_Client_0    11       0   24/3/2014   \n",
       "1     101  31/12/1994   60  train_Client_0    11       0   29/3/2013   \n",
       "2     101  31/12/1994   60  train_Client_0    11       0   23/3/2015   \n",
       "3     101  31/12/1994   60  train_Client_0    11       0   13/7/2015   \n",
       "4     101  31/12/1994   60  train_Client_0    11       0  17/11/2016   \n",
       "\n",
       "   tarif_type  counter_number  counter_statue  ...  reading_remarque  \\\n",
       "0          11       1335667.0               0  ...                 8   \n",
       "1          11       1335667.0               0  ...                 6   \n",
       "2          11       1335667.0               0  ...                 8   \n",
       "3          11       1335667.0               0  ...                 8   \n",
       "4          11       1335667.0               0  ...                 9   \n",
       "\n",
       "   consommation_level_4  old_index  new_index  months_number  counter_type  \\\n",
       "0                     0      14302      14384              4          ELEC   \n",
       "1                     0      12294      13678              4          ELEC   \n",
       "2                     0      14624      14747              4          ELEC   \n",
       "3                     0      14747      14849              4          ELEC   \n",
       "4                     0      15066      15638             12          ELEC   \n",
       "\n",
       "  counter_coefficient  consommation_level_1  consommation_level_2  \\\n",
       "0                   1                    82                     0   \n",
       "1                   1                  1200                   184   \n",
       "2                   1                   123                     0   \n",
       "3                   1                   102                     0   \n",
       "4                   1                   572                     0   \n",
       "\n",
       "   consommation_level_3  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>dis</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>counter_code</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>5.006510e+05</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "      <td>500651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>204.746922</td>\n",
       "      <td>63.519156</td>\n",
       "      <td>11.353871</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>16.108279</td>\n",
       "      <td>1.951034e+11</td>\n",
       "      <td>0.050217</td>\n",
       "      <td>204.390755</td>\n",
       "      <td>7.463710</td>\n",
       "      <td>64.393150</td>\n",
       "      <td>1.575969e+04</td>\n",
       "      <td>1.639037e+04</td>\n",
       "      <td>22.744289</td>\n",
       "      <td>1.000154</td>\n",
       "      <td>443.065463</td>\n",
       "      <td>120.508706</td>\n",
       "      <td>28.196772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.620488</td>\n",
       "      <td>3.388720</td>\n",
       "      <td>3.661420</td>\n",
       "      <td>0.242323</td>\n",
       "      <td>11.145881</td>\n",
       "      <td>2.071552e+12</td>\n",
       "      <td>0.396153</td>\n",
       "      <td>121.204514</td>\n",
       "      <td>1.374409</td>\n",
       "      <td>1230.465569</td>\n",
       "      <td>2.975733e+04</td>\n",
       "      <td>3.053707e+04</td>\n",
       "      <td>1670.624818</td>\n",
       "      <td>0.047150</td>\n",
       "      <td>592.249623</td>\n",
       "      <td>1396.817086</td>\n",
       "      <td>214.020756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.477220e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.799000e+03</td>\n",
       "      <td>2.165000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.857010e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.876000e+03</td>\n",
       "      <td>8.438000e+03</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.008740e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.092750e+04</td>\n",
       "      <td>2.164500e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>661.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.740000e+13</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>343568.000000</td>\n",
       "      <td>2.800280e+06</td>\n",
       "      <td>2.870972e+06</td>\n",
       "      <td>231602.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>98889.000000</td>\n",
       "      <td>819886.000000</td>\n",
       "      <td>45360.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              region            dis           catg         target  \\\n",
       "count  500651.000000  500651.000000  500651.000000  500651.000000   \n",
       "mean      204.746922      63.519156      11.353871       0.062644   \n",
       "std       104.620488       3.388720       3.661420       0.242323   \n",
       "min       101.000000      60.000000      11.000000       0.000000   \n",
       "25%       101.000000      62.000000      11.000000       0.000000   \n",
       "50%       107.000000      62.000000      11.000000       0.000000   \n",
       "75%       307.000000      69.000000      11.000000       0.000000   \n",
       "max       399.000000      69.000000      51.000000       1.000000   \n",
       "\n",
       "          tarif_type  counter_number  counter_statue   counter_code  \\\n",
       "count  500651.000000    5.006510e+05   500651.000000  500651.000000   \n",
       "mean       16.108279    1.951034e+11        0.050217     204.390755   \n",
       "std        11.145881    2.071552e+12        0.396153     121.204514   \n",
       "min         9.000000    0.000000e+00        0.000000       5.000000   \n",
       "25%        11.000000    1.477220e+05        0.000000     202.000000   \n",
       "50%        11.000000    4.857010e+05        0.000000     203.000000   \n",
       "75%        11.000000    1.008740e+06        0.000000     207.000000   \n",
       "max        45.000000    2.740000e+13        5.000000     600.000000   \n",
       "\n",
       "       reading_remarque  consommation_level_4     old_index     new_index  \\\n",
       "count     500651.000000         500651.000000  5.006510e+05  5.006510e+05   \n",
       "mean           7.463710             64.393150  1.575969e+04  1.639037e+04   \n",
       "std            1.374409           1230.465569  2.975733e+04  3.053707e+04   \n",
       "min            6.000000              0.000000  0.000000e+00  0.000000e+00   \n",
       "25%            6.000000              0.000000  1.799000e+03  2.165000e+03   \n",
       "50%            8.000000              0.000000  7.876000e+03  8.438000e+03   \n",
       "75%            9.000000              0.000000  2.092750e+04  2.164500e+04   \n",
       "max            9.000000         343568.000000  2.800280e+06  2.870972e+06   \n",
       "\n",
       "       months_number  counter_coefficient  consommation_level_1  \\\n",
       "count  500651.000000        500651.000000         500651.000000   \n",
       "mean       22.744289             1.000154            443.065463   \n",
       "std      1670.624818             0.047150            592.249623   \n",
       "min         1.000000             1.000000              0.000000   \n",
       "25%         4.000000             1.000000             99.000000   \n",
       "50%         4.000000             1.000000            321.000000   \n",
       "75%         4.000000             1.000000            661.000000   \n",
       "max    231602.000000            20.000000          98889.000000   \n",
       "\n",
       "       consommation_level_2  consommation_level_3  \n",
       "count         500651.000000         500651.000000  \n",
       "mean             120.508706             28.196772  \n",
       "std             1396.817086            214.020756  \n",
       "min                0.000000              0.000000  \n",
       "25%                0.000000              0.000000  \n",
       "50%                0.000000              0.000000  \n",
       "75%                0.000000              0.000000  \n",
       "max           819886.000000          45360.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>date_x</th>\n",
       "      <th>dis</th>\n",
       "      <th>id</th>\n",
       "      <th>catg</th>\n",
       "      <th>target</th>\n",
       "      <th>date_y</th>\n",
       "      <th>tarif_type</th>\n",
       "      <th>counter_number</th>\n",
       "      <th>counter_statue</th>\n",
       "      <th>...</th>\n",
       "      <th>reading_remarque</th>\n",
       "      <th>consommation_level_4</th>\n",
       "      <th>old_index</th>\n",
       "      <th>new_index</th>\n",
       "      <th>months_number</th>\n",
       "      <th>counter_type</th>\n",
       "      <th>counter_coefficient</th>\n",
       "      <th>consommation_level_1</th>\n",
       "      <th>consommation_level_2</th>\n",
       "      <th>consommation_level_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>24/3/2014</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14302</td>\n",
       "      <td>14384</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>29/3/2013</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12294</td>\n",
       "      <td>13678</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>1200</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>23/3/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14624</td>\n",
       "      <td>14747</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13/7/2015</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>14747</td>\n",
       "      <td>14849</td>\n",
       "      <td>4</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>31/12/1994</td>\n",
       "      <td>60</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>17/11/2016</td>\n",
       "      <td>11</td>\n",
       "      <td>1335667.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>15066</td>\n",
       "      <td>15638</td>\n",
       "      <td>12</td>\n",
       "      <td>ELEC</td>\n",
       "      <td>1</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   region      date_x  dis              id  catg  target      date_y  \\\n",
       "0     101  31/12/1994   60  train_Client_0    11       0   24/3/2014   \n",
       "1     101  31/12/1994   60  train_Client_0    11       0   29/3/2013   \n",
       "2     101  31/12/1994   60  train_Client_0    11       0   23/3/2015   \n",
       "3     101  31/12/1994   60  train_Client_0    11       0   13/7/2015   \n",
       "4     101  31/12/1994   60  train_Client_0    11       0  17/11/2016   \n",
       "\n",
       "   tarif_type  counter_number  counter_statue  ...  reading_remarque  \\\n",
       "0          11       1335667.0               0  ...                 8   \n",
       "1          11       1335667.0               0  ...                 6   \n",
       "2          11       1335667.0               0  ...                 8   \n",
       "3          11       1335667.0               0  ...                 8   \n",
       "4          11       1335667.0               0  ...                 9   \n",
       "\n",
       "   consommation_level_4  old_index  new_index  months_number  counter_type  \\\n",
       "0                     0      14302      14384              4          ELEC   \n",
       "1                     0      12294      13678              4          ELEC   \n",
       "2                     0      14624      14747              4          ELEC   \n",
       "3                     0      14747      14849              4          ELEC   \n",
       "4                     0      15066      15638             12          ELEC   \n",
       "\n",
       "  counter_coefficient  consommation_level_1  consommation_level_2  \\\n",
       "0                   1                    82                     0   \n",
       "1                   1                  1200                   184   \n",
       "2                   1                   123                     0   \n",
       "3                   1                   102                     0   \n",
       "4                   1                   572                     0   \n",
       "\n",
       "   consommation_level_3  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 500651\n",
      "Number of datapoints in each column: \n",
      "region                  500651\n",
      "date_x                  500651\n",
      "dis                     500651\n",
      "id                      500651\n",
      "catg                    500651\n",
      "target                  500651\n",
      "date_y                  500651\n",
      "tarif_type              500651\n",
      "counter_number          500651\n",
      "counter_statue          500651\n",
      "counter_code            500651\n",
      "reading_remarque        500651\n",
      "consommation_level_4    500651\n",
      "old_index               500651\n",
      "new_index               500651\n",
      "months_number           500651\n",
      "counter_type            500651\n",
      "counter_coefficient     500651\n",
      "consommation_level_1    500651\n",
      "consommation_level_2    500651\n",
      "consommation_level_3    500651\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset: {len(combined_df)}\")\n",
    "print(f\"Number of datapoints in each column: \\n{combined_df.count()} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31363\n",
      "proportion of fraud: 0.06264443694310008\n"
     ]
    }
   ],
   "source": [
    "number_of_fraud = sum(combined_df[\"target\"] == 1)\n",
    "print(number_of_fraud)\n",
    "print(f\"proportion of fraud: {number_of_fraud/len(combined_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have created 4 new variables, described as such:\n",
    "##### delta_start_invoice: diff between join and transaction date\n",
    "##### delta_index: diff between old and new index\n",
    "##### delta_transactions: diff between transactions over the same client\n",
    "##### consommation_sum: sum of consommation levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>join_date</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>id</th>\n",
       "      <th>delta_start_invoice</th>\n",
       "      <th>delta_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2005-10-17</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>3943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-02-24</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4073</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-06-23</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4192</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2006-10-18</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4309</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1994-12-31</td>\n",
       "      <td>2007-02-26</td>\n",
       "      <td>train_Client_0</td>\n",
       "      <td>4440</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    join_date transaction_date              id  delta_start_invoice  \\\n",
       "22 1994-12-31       2005-10-17  train_Client_0                 3943   \n",
       "23 1994-12-31       2006-02-24  train_Client_0                 4073   \n",
       "24 1994-12-31       2006-06-23  train_Client_0                 4192   \n",
       "25 1994-12-31       2006-10-18  train_Client_0                 4309   \n",
       "28 1994-12-31       2007-02-26  train_Client_0                 4440   \n",
       "\n",
       "    delta_transactions  \n",
       "22                 0.0  \n",
       "23               130.0  \n",
       "24               119.0  \n",
       "25               117.0  \n",
       "28               131.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dates = {'join_date': combined_df['date_x'], 'transaction_date': combined_df['date_y'], 'id': combined_df['id']}\n",
    "dates_df = pd.DataFrame(dates)\n",
    "\n",
    "dates_df['join_date'] = pd.to_datetime(dates_df['join_date'] , format='%d/%m/%Y')\n",
    "dates_df['transaction_date'] = pd.to_datetime(dates_df['transaction_date'], format='%d/%m/%Y')\n",
    "\n",
    "# Calculate the difference in days between transaction and join date\n",
    "dates_df['delta_start_invoice'] = (dates_df['transaction_date']- dates_df['join_date']).dt.days\n",
    "\n",
    "# Create new delta_transactions (diff between transaction dates for each client)\n",
    "dates_df = dates_df.sort_values(['id', 'delta_start_invoice'])\n",
    "dates_df['delta_transactions'] = dates_df.groupby('id')['delta_start_invoice'].diff().fillna(0)\n",
    "\n",
    "dates_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add new delta_start_invoice, delta_index and consommation_sum to combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['delta_index'] = combined_df['new_index'] - combined_df['old_index']\n",
    "combined_df['delta_start_invoice'] = dates_df['delta_start_invoice']\n",
    "combined_df['delta_transactions'] = dates_df['delta_transactions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new dataframe for one-hot encoding categorical variables (dis, catg, region, tarif_type, counter_statue, counter_code, reading_remarque, counter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['dis', 'catg', 'region', 'tarif_type', 'counter_statue', 'counter_code', 'counter_type']\n",
    "categorical_df = pd.get_dummies(combined_df, columns=categorical_vars, prefix=categorical_vars)\n",
    "categorical_df = categorical_df.groupby('id').agg({col: 'max' for col in categorical_df.columns if col != 'id'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agg function to group the transactions with each client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">consommation_level_1</th>\n",
       "      <th colspan=\"4\" halign=\"left\">consommation_level_2</th>\n",
       "      <th colspan=\"2\" halign=\"left\">consommation_level_3</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">delta_index</th>\n",
       "      <th colspan=\"4\" halign=\"left\">delta_start_invoice</th>\n",
       "      <th colspan=\"4\" halign=\"left\">reading_remarque</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_Client_0</th>\n",
       "      <td>12334</td>\n",
       "      <td>352.400000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>310.343472</td>\n",
       "      <td>370</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.568935</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>267.0</td>\n",
       "      <td>341.553930</td>\n",
       "      <td>213142</td>\n",
       "      <td>6089.771429</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>1358.574709</td>\n",
       "      <td>244</td>\n",
       "      <td>6.971429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.248192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_1</th>\n",
       "      <td>20629</td>\n",
       "      <td>557.540541</td>\n",
       "      <td>520.0</td>\n",
       "      <td>197.935960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>520.0</td>\n",
       "      <td>197.935960</td>\n",
       "      <td>132603</td>\n",
       "      <td>3583.864865</td>\n",
       "      <td>3509.0</td>\n",
       "      <td>1457.748762</td>\n",
       "      <td>267</td>\n",
       "      <td>7.216216</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.377097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_10</th>\n",
       "      <td>14375</td>\n",
       "      <td>798.611111</td>\n",
       "      <td>655.5</td>\n",
       "      <td>513.841374</td>\n",
       "      <td>682</td>\n",
       "      <td>37.888889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.748942</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>655.5</td>\n",
       "      <td>646.808386</td>\n",
       "      <td>165982</td>\n",
       "      <td>9221.222222</td>\n",
       "      <td>8678.0</td>\n",
       "      <td>1526.789733</td>\n",
       "      <td>127</td>\n",
       "      <td>7.055556</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.258955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_100</th>\n",
       "      <td>24</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.607011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.607011</td>\n",
       "      <td>91275</td>\n",
       "      <td>4563.750000</td>\n",
       "      <td>4545.5</td>\n",
       "      <td>774.520692</td>\n",
       "      <td>123</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_Client_1000</th>\n",
       "      <td>9292</td>\n",
       "      <td>663.714286</td>\n",
       "      <td>770.0</td>\n",
       "      <td>224.831365</td>\n",
       "      <td>1468</td>\n",
       "      <td>104.857143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167.155320</td>\n",
       "      <td>1643</td>\n",
       "      <td>117.357143</td>\n",
       "      <td>...</td>\n",
       "      <td>770.0</td>\n",
       "      <td>633.485669</td>\n",
       "      <td>13497</td>\n",
       "      <td>964.071429</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>506.611437</td>\n",
       "      <td>124</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.363137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  consommation_level_1                                 \\\n",
       "                                   sum        mean median         std   \n",
       "id                                                                      \n",
       "train_Client_0                   12334  352.400000  267.0  310.343472   \n",
       "train_Client_1                   20629  557.540541  520.0  197.935960   \n",
       "train_Client_10                  14375  798.611111  655.5  513.841374   \n",
       "train_Client_100                    24    1.200000    0.0    3.607011   \n",
       "train_Client_1000                 9292  663.714286  770.0  224.831365   \n",
       "\n",
       "                  consommation_level_2                                 \\\n",
       "                                   sum        mean median         std   \n",
       "id                                                                      \n",
       "train_Client_0                     370   10.571429    0.0   43.568935   \n",
       "train_Client_1                       0    0.000000    0.0    0.000000   \n",
       "train_Client_10                    682   37.888889    0.0  160.748942   \n",
       "train_Client_100                     0    0.000000    0.0    0.000000   \n",
       "train_Client_1000                 1468  104.857143    0.0  167.155320   \n",
       "\n",
       "                  consommation_level_3              ... delta_index  \\\n",
       "                                   sum        mean  ...      median   \n",
       "id                                                  ...               \n",
       "train_Client_0                       0    0.000000  ...       267.0   \n",
       "train_Client_1                       0    0.000000  ...       520.0   \n",
       "train_Client_10                      0    0.000000  ...       655.5   \n",
       "train_Client_100                     0    0.000000  ...         0.0   \n",
       "train_Client_1000                 1643  117.357143  ...       770.0   \n",
       "\n",
       "                              delta_start_invoice                       \\\n",
       "                          std                 sum         mean  median   \n",
       "id                                                                       \n",
       "train_Client_0     341.553930              213142  6089.771429  6047.0   \n",
       "train_Client_1     197.935960              132603  3583.864865  3509.0   \n",
       "train_Client_10    646.808386              165982  9221.222222  8678.0   \n",
       "train_Client_100     3.607011               91275  4563.750000  4545.5   \n",
       "train_Client_1000  633.485669               13497   964.071429  1010.0   \n",
       "\n",
       "                               reading_remarque                             \n",
       "                           std              sum      mean median       std  \n",
       "id                                                                          \n",
       "train_Client_0     1358.574709              244  6.971429    6.0  1.248192  \n",
       "train_Client_1     1457.748762              267  7.216216    6.0  1.377097  \n",
       "train_Client_10    1526.789733              127  7.055556    6.0  1.258955  \n",
       "train_Client_100    774.520692              123  6.150000    6.0  0.670820  \n",
       "train_Client_1000   506.611437              124  8.857143    9.0  0.363137  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = ['sum', 'mean', 'median', 'std']\n",
    "\n",
    "selected_columns = ['consommation_level_1', \n",
    "                    'consommation_level_2', 'consommation_level_3', 'consommation_level_4',\n",
    "                    'delta_index', 'delta_start_invoice', 'id', 'reading_remarque']\n",
    "\n",
    "# Create a new dataframe with the desired aggregate functions\n",
    "numerical_df = combined_df[selected_columns].groupby('id').agg(stats)\n",
    "\n",
    "numerical_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining numerical and cat dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21652 entries, train_Client_0 to train_Client_128438\n",
      "Columns: 116 entries, ('consommation_level_1', 'sum') to counter_type_GAZ\n",
      "dtypes: bool(85), float64(22), int64(9)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "to_drop = ['region', 'date_x', 'dis', 'id', 'catg', 'target', 'date_y', 'tarif_type', 'counter_number', \n",
    "           'counter_statue', 'counter_code', 'reading_remarque', 'consommation_level_4', 'old_index',\n",
    "           'new_index', 'months_number', 'counter_type', 'counter_coefficient', 'consommation_level_1',\n",
    "           'consommation_level_2', 'consommation_level_3']\n",
    "\n",
    "client_summary = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "\n",
    "# Identify existing columns in the DataFrame\n",
    "existing_columns = [col for col in to_drop if col in client_summary.columns]\n",
    "\n",
    "# Drop existing columns from the DataFrame\n",
    "client_summary = client_summary.drop(columns=existing_columns)\n",
    "\n",
    "client_summary.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add y variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    20576\n",
       "1     1076\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_summary['target'] = combined_df.groupby('id')['target'].apply(lambda x: 1 if x.any() else 0)\n",
    "client_summary['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    20576\n",
       "1     1076\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.groupby('id')['target'].apply(lambda x: 1 if x.any() else 0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the low proportion of fraud cases, we performed synthetic oversampling of fraud cases with SMOTE and undersampled non-fraud cases with Tomek's link with three different methods:\n",
    "#### 1) SMOTE + Tomek's Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [consommation_level_1sum, consommation_level_1mean, consommation_level_1median, consommation_level_1std, consommation_level_2sum, consommation_level_2mean, consommation_level_2median, consommation_level_2std, consommation_level_3sum, consommation_level_3mean, consommation_level_3median, consommation_level_3std, consommation_level_4sum, consommation_level_4mean, consommation_level_4median, consommation_level_4std, delta_indexsum, delta_indexmean, delta_indexmedian, delta_indexstd, delta_start_invoicesum, delta_start_invoicemean, delta_start_invoicemedian, delta_start_invoicestd, reading_remarquesum, reading_remarquemean, reading_remarquemedian, reading_remarquestd, delta_index, delta_start_invoice, delta_transactions, dis_60, dis_62, dis_63, dis_69, catg_11, catg_12, catg_51, region_101, region_103, region_104, region_105, region_106, region_107, region_206, region_301, region_302, region_303, region_304, region_305, region_306, region_307, region_308, region_309, region_310, region_311, region_312, region_313, region_371, region_372, region_379, region_399, tarif_type_9, tarif_type_10, tarif_type_11, tarif_type_12, tarif_type_13, tarif_type_14, tarif_type_15, tarif_type_21, tarif_type_29, tarif_type_30, tarif_type_40, tarif_type_45, counter_statue_0, counter_statue_1, counter_statue_2, counter_statue_3, counter_statue_4, counter_statue_5, counter_code_5, counter_code_10, counter_code_25, counter_code_40, counter_code_101, counter_code_102, counter_code_201, counter_code_202, counter_code_203, counter_code_204, counter_code_207, counter_code_210, counter_code_214, counter_code_222, counter_code_303, counter_code_305, counter_code_307, counter_code_310, counter_code_333, counter_code_403, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 116 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the oversampling strategy using SMOTE and Tomek\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "\n",
    "smote = SMOTE(random_state=seed)\n",
    "tomek = TomekLinks()\n",
    "\n",
    "X = client_summary.drop('target', axis=1)\n",
    "\n",
    "# Flatten multi-level column names\n",
    "X.columns = [''.join(map(str, col)).strip() for col in X.columns.to_flat_index()]\n",
    "\n",
    "y = client_summary['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= seed)\n",
    "\n",
    "print(X_train[X_train.isnull().any(axis=1)])\n",
    "\n",
    "\n",
    "# under and oversampling of data using Tomek and SMOTE\n",
    "X_train1, y_train1 = tomek.fit_resample(X_train, y_train)\n",
    "X_train1_resampled, y_train1_resampled = smote.fit_resample(X_train1, y_train1)\n",
    "\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train1_standardized = pd.DataFrame(scaler.fit_transform(X_train1_resampled), columns=X_train1_resampled.columns)\n",
    "X_test_standardized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Norminalise the data\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train1_norminalized = pd.DataFrame(scaler_minmax.fit_transform(X_train1_resampled), columns=X_train1_resampled.columns)\n",
    "# X_test_norminalized = pd.DataFrame(scaler_minmax.transform(X_test), columns=X_test.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) SMOTE only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the oversampling strategy using SMOTE only\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "smote = SMOTE(random_state=seed)\n",
    "\n",
    "X = client_summary.drop('target', axis=1)\n",
    "\n",
    "# Flatten multi-level column names\n",
    "X.columns = [''.join(map(str, col)).strip() for col in X.columns.to_flat_index()]\n",
    "\n",
    "y = client_summary['target']\n",
    "\n",
    "X_train2, X_test, y_train2, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Oversampling of data using SMOTE\n",
    "X_train2, y_train2 = smote.fit_resample(X_train2, y_train2)\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train2_standardized = pd.DataFrame(scaler.fit_transform(X_train2), columns=X_train2.columns)\n",
    "X_test_standardized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Tomek's Link only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the undersampling strategy using Tomek's Link only\n",
    "tomek = TomekLinks()\n",
    "\n",
    "X = client_summary.drop('target', axis=1)\n",
    "\n",
    "# Flatten multi-level column names\n",
    "X.columns = [''.join(map(str, col)).strip() for col in X.columns.to_flat_index()]\n",
    "\n",
    "y = client_summary['target']\n",
    "\n",
    "X_train3, X_test, y_train3, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Undersampling of data using Tomek Links\n",
    "X_train3, y_train3 = tomek.fit_resample(X_train3, y_train3)\n",
    "\n",
    "# Standardize the data separately to prevent leakage\n",
    "scaler = StandardScaler()\n",
    "X_train3_standardized = pd.DataFrame(scaler.fit_transform(X_train3), columns=X_train3.columns)\n",
    "X_test_standardized = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16461\n",
       "1      860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4115\n",
       "1     216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16111\n",
       "1    16111\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE + Tomak's Link\n",
    "y_train1_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16461\n",
       "1    16461\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE\n",
    "y_train2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    16111\n",
       "1      860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tomak's link\n",
    "y_train3.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Bool to int\n",
    "X_train1_resampled = X_train1_resampled.astype({col: int for col in X_train1_resampled.select_dtypes(include='bool').columns})\n",
    "X_train2 = X_train2.astype({col: int for col in X_train2.select_dtypes(include='bool').columns})\n",
    "X_train3 = X_train3.astype({col: int for col in X_train3.select_dtypes(include='bool').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['consommation_level_3sum', 'consommation_level_3mean', 'consommation_level_3std', 'consommation_level_2sum', 'consommation_level_2std', 'consommation_level_2mean', 'consommation_level_4sum', 'consommation_level_4std', 'consommation_level_4mean', 'delta_index', 'delta_indexsum', 'delta_indexstd', 'dis_69', 'consommation_level_1sum', 'delta_start_invoicestd', 'reading_remarquesum', 'consommation_level_1std', 'counter_statue_5', 'counter_code_203', 'counter_code_413']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Xander\\Documents\\Lib\\site-packages\\pandas\\core\\nanops.py:1632: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  return spearmanr(a, b)[0]\n"
     ]
    }
   ],
   "source": [
    "# top 20 vars with highest correlation\n",
    "corr_matrix_std = X_train1_standardized.corrwith(y_train1_resampled, method='spearman')\n",
    "\n",
    "top_20_vars = corr_matrix_std.abs().sort_values(ascending=False).head(20).index.tolist()\n",
    "\n",
    "print(top_20_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                 Variable1                 Variable2  Correlation\n",
      "0      1          counter_statue_5                    dis_69     0.001869\n",
      "1      2                    dis_69          counter_statue_5     0.001869\n",
      "2      3          counter_code_413       reading_remarquesum     0.002269\n",
      "3      4       reading_remarquesum          counter_code_413     0.002269\n",
      "4      5          counter_statue_5          counter_code_413     0.007266\n",
      "5      6          counter_code_413          counter_statue_5     0.007266\n",
      "6      7    delta_start_invoicestd  consommation_level_4mean     0.014489\n",
      "7      8  consommation_level_4mean    delta_start_invoicestd     0.014489\n",
      "8      9            delta_indexsum          counter_code_203     0.014550\n",
      "9     10          counter_code_203            delta_indexsum     0.014550\n",
      "10    11                    dis_69       reading_remarquesum     0.017995\n",
      "11    12       reading_remarquesum                    dis_69     0.017995\n",
      "12    13   consommation_level_4std    delta_start_invoicestd     0.018355\n",
      "13    14    delta_start_invoicestd   consommation_level_4std     0.018355\n",
      "14    15    delta_start_invoicestd   consommation_level_4sum     0.027520\n",
      "15    16   consommation_level_4sum    delta_start_invoicestd     0.027520\n",
      "16    17          counter_code_203   consommation_level_1std     0.052838\n",
      "17    18   consommation_level_1std          counter_code_203     0.052838\n",
      "18    19  consommation_level_4mean          counter_statue_5     0.053769\n",
      "19    20          counter_statue_5  consommation_level_4mean     0.053769\n",
      "20    21          counter_statue_5   consommation_level_4std     0.056103\n",
      "21    22   consommation_level_4std          counter_statue_5     0.056103\n",
      "22    23   consommation_level_4sum          counter_statue_5     0.058655\n",
      "23    24          counter_statue_5   consommation_level_4sum     0.058655\n",
      "24    25    delta_start_invoicestd  consommation_level_3mean     0.058702\n",
      "25    26  consommation_level_3mean    delta_start_invoicestd     0.058702\n",
      "26    27    delta_start_invoicestd          counter_code_413     0.063476\n",
      "27    28          counter_code_413    delta_start_invoicestd     0.063476\n",
      "28    29  consommation_level_3mean          counter_statue_5     0.073444\n",
      "29    30          counter_statue_5  consommation_level_3mean     0.073444\n",
      "30    31    delta_start_invoicestd   consommation_level_3std     0.075807\n",
      "31    32   consommation_level_3std    delta_start_invoicestd     0.075807\n",
      "32    33   consommation_level_3std          counter_statue_5     0.081324\n",
      "33    34          counter_statue_5   consommation_level_3std     0.081324\n",
      "34    35   consommation_level_1sum                    dis_69     0.081585\n",
      "35    36                    dis_69   consommation_level_1sum     0.081585\n",
      "36    37            delta_indexstd          counter_statue_5     0.088931\n",
      "37    38          counter_statue_5            delta_indexstd     0.088931\n",
      "38    39          counter_statue_5   consommation_level_3sum     0.091687\n",
      "39    40   consommation_level_3sum          counter_statue_5     0.091687\n"
     ]
    }
   ],
   "source": [
    "# Picking 20 vars to keep (with lowest collinearity)\n",
    "\n",
    "# Create a subset of the dataset with only the top 20 variables\n",
    "X_top20 = X_train1_standardized[top_20_vars]\n",
    "\n",
    "# Remove constant columns from X_top20\n",
    "X_top20 = X_top20.loc[:, (X_top20 != X_top20.iloc[0]).any()]\n",
    "\n",
    "# Calculate correlation matrix between top 20 variables\n",
    "new_corr_matrix_std = X_top20.corr(method='spearman')\n",
    "\n",
    "# Convert the correlation matrix to a DataFrame\n",
    "corr_df = new_corr_matrix_std.reset_index().melt('index', var_name='Variable2', value_name='Correlation')\n",
    "corr_df.columns = ['Variable1', 'Variable2', 'Correlation']\n",
    "\n",
    "# Remove self-correlations (diagonal elements)\n",
    "corr_df = corr_df[corr_df['Variable1'] != corr_df['Variable2']]\n",
    "\n",
    "corr_df['Correlation'] = corr_df['Correlation'].abs()\n",
    "\n",
    "# Rank the pairs based on correlation (descending)\n",
    "corr_df = corr_df.sort_values(by='Correlation', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Add a ranking column\n",
    "corr_df.insert(0, 'Rank', range(1, len(corr_df)+1))\n",
    "\n",
    "# Print the table\n",
    "print(corr_df.head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the correlation matrix, we pick the top 10 vars with lowest collinearity for the baseline logistic regression model\n",
    "# using method 1 (SMOTE + Tomak's Link)\n",
    "\n",
    "top_10_vars = ['counter_statue_5', 'dis_69', 'counter_code_413', 'reading_remarquesum', 'delta_start_invoicestd',\n",
    "'consommation_level_4mean', 'delta_indexsum', 'counter_code_203', 'consommation_level_4std', 'consommation_level_4sum']\n",
    "\n",
    "X_train1_standardized_resampled_important = X_train1_standardized[top_10_vars]\n",
    "X_train1_norminalized_resampled_important = X_train1_norminalized[top_10_vars]\n",
    "X_train2_standardized_important = X_train2_standardized[top_10_vars]\n",
    "X_train3_standardized_important = X_train3_standardized[top_10_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training std dataset shape (method 1): (32222, 10)\n",
      "Training nom dataset shape (method 1): (32222, 10)\n",
      "Training std dataset shape (method 2): (32922, 10)\n",
      "Training std dataset shape (method 3): (16971, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training std dataset shape (method 1): {X_train1_standardized_resampled_important.shape}\")\n",
    "print(f\"Training nom dataset shape (method 1): {X_train1_norminalized_resampled_important.shape}\")\n",
    "print(f\"Training std dataset shape (method 2): {X_train2_standardized_important.shape}\")\n",
    "print(f\"Training std dataset shape (method 3): {X_train3_standardized_important.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores (method 1) (std): [0.69987021 0.75429975 0.75460123 0.7496136  0.74361342]\n",
      "Mean F1 Score (method 1) (std): 0.74039964323809\n",
      "Cross-Validation F1 Scores (method 1) (nom): [0.6913178  0.74888787 0.74911552 0.7442866  0.73904997]\n",
      "Mean F1 Score (method 1) (nom): 0.7345315513896734\n"
     ]
    }
   ],
   "source": [
    "# Comparing performance of standardized and nominalized datasets for method 1 (SMOTE + Tomak's Link)\n",
    "\n",
    "# Initialize logistic regression model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# Perform cross-validation (std)\n",
    "cross_val_results_std = cross_val_score(model_LR, X_train1_standardized_resampled_important, y_train1_resampled, cv=5, scoring='f1')\n",
    "\n",
    "# Print cross-validation F1 score (std)\n",
    "print(\"Cross-Validation F1 Scores (method 1) (std):\", cross_val_results_std)\n",
    "print(\"Mean F1 Score (method 1) (std):\", cross_val_results_std.mean())\n",
    "\n",
    "# Perform cross-validation (nom)\n",
    "cross_val_results_nom = cross_val_score(model_LR, X_train1_norminalized_resampled_important, y_train1_resampled, cv=5, scoring='f1')\n",
    "\n",
    "# Print cross-validation F1 score (nom)\n",
    "print(\"Cross-Validation F1 Scores (method 1) (nom):\", cross_val_results_nom)\n",
    "print(\"Mean F1 Score (method 1) (nom):\", cross_val_results_nom.mean())\n",
    "\n",
    "# We pick standardising over norminalizing given its slightly better mean F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F1 Scores (method 2) (std): [0.69572158 0.75192047 0.75045154 0.7496977  0.74861007]\n",
      "Mean F1 Score (method 2) (std): 0.7392802717960579\n",
      "Cross-Validation F1 Scores (method 3) (std): [0. 0. 0. 0. 0.]\n",
      "Mean F1 Score (method 3) (std): 0.0\n"
     ]
    }
   ],
   "source": [
    "# Now, running logistic regression on standardised datasets for method 2 (SMOTE only) and method 3 (Tomak's Link only)\n",
    "\n",
    "# Perform cross-validation (method 2)\n",
    "cross_val_results_m2 = cross_val_score(model_LR, X_train2_standardized_important, y_train2, cv=5, scoring='f1')\n",
    "\n",
    "# Print cross-validation F1 score (method 2)\n",
    "print(\"Cross-Validation F1 Scores (method 2) (std):\", cross_val_results_m2)\n",
    "print(\"Mean F1 Score (method 2) (std):\", cross_val_results_m2.mean())\n",
    "\n",
    "# Perform cross-validation (method 3)\n",
    "cross_val_results_m3 = cross_val_score(model_LR, X_train3_standardized_important, y_train3, cv=5, scoring='f1')\n",
    "\n",
    "# Print cross-validation F1 score (method 2)\n",
    "print(\"Cross-Validation F1 Scores (method 3) (std):\", cross_val_results_m3)\n",
    "print(\"Mean F1 Score (method 3) (std):\", cross_val_results_m3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.60003846 0.68719042 0.68580742 0.68055905 0.68334064]\n",
      "Mean F2 Score: 0.6673871992387312\n"
     ]
    }
   ],
   "source": [
    "# Create an SVM classifier\n",
    "SVM = svm.SVC(kernel='linear')\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "# Make scorer\n",
    "f2_scorer = make_scorer(f2_score)\n",
    "\n",
    "cross_val_results_m2_svm = cross_val_score(SVM, X_train2_standardized_important, y_train2, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m2_svm)\n",
    "print(\"Mean F2 Score:\", cross_val_results_m2_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13169, number of negative: 13168\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1542\n",
      "[LightGBM] [Info] Number of data points in the train set: 26337, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "[LightGBM] [Info] Number of positive: 13168, number of negative: 13169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1542\n",
      "[LightGBM] [Info] Number of data points in the train set: 26337, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499981 -> initscore=-0.000076\n",
      "[LightGBM] [Info] Start training from score -0.000076\n",
      "[LightGBM] [Info] Number of positive: 13169, number of negative: 13169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1542\n",
      "[LightGBM] [Info] Number of data points in the train set: 26338, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13169, number of negative: 13169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1542\n",
      "[LightGBM] [Info] Number of data points in the train set: 26338, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 13169, number of negative: 13169\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1542\n",
      "[LightGBM] [Info] Number of data points in the train set: 26338, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Cross-Validation F2 Scores: [0.77340445 0.83600218 0.8382131  0.83710817 0.83378582]\n",
      "Mean F2 Score: 0.8237027440085676\n"
     ]
    }
   ],
   "source": [
    "# Create a LightGBM classifier\n",
    "GBM = lgb.LGBMClassifier()\n",
    "\n",
    "cross_val_results_m2_gbm = cross_val_score(GBM, X_train2_standardized_important, y_train2, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m2_gbm)\n",
    "print(\"Mean F2 Score:\", cross_val_results_m2_gbm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation F2 Scores: [0.85019751 0.904839   0.90422975 0.90533253 0.90342306]\n",
      "Mean F2 Score: 0.8936043702526089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "RF = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cross_val_results_m2_rf = cross_val_score(RF, X_train2_standardized_important, y_train2, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m2_rf)\n",
    "print(\"Mean F2 Score:\", cross_val_results_m2_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ADA boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create an AdaBoost classifier with Decision Tree as the base estimator\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m ADA \u001b[38;5;241m=\u001b[39m \u001b[43mAdaBoostClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m cross_val_results_m2_ada \u001b[38;5;241m=\u001b[39m cross_val_score(ADA, X_train2_standardized_important, y_train2, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mf2_scorer)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-Validation F2 Scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cross_val_results_m2_ada)\n",
      "\u001b[1;31mTypeError\u001b[0m: AdaBoostClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Create an AdaBoost classifier with Decision Tree as the base estimator\n",
    "ADA = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=200)\n",
    "\n",
    "cross_val_results_m2_ada = cross_val_score(ADA, X_train2_standardized_important, y_train2, cv=5, scoring=f2_scorer)\n",
    "print(\"Cross-Validation F2 Scores:\", cross_val_results_m2_ada)\n",
    "print(\"Mean F2 Score:\", cross_val_results_m2_ada.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Assuming you have the true labels (y_true) and predicted labels (y_pred)\n",
    "f2_score = fbeta_score(y_true, y_pred, beta=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
